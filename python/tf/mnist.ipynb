{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refer to: https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "10000/1 - 0s - loss: 0.1936 - accuracy: 0.9268\n",
      "* finish test, lost is 0.2708414345532656, accuracy is 0.926800012588501\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result number is: 8\n"
     ]
    }
   ],
   "source": [
    "import random as rdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('* train and test data loaded, shape is: {}'.format(x_train.shape))\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_num_softmax'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "random_idx = rdm.randint(0, len(x_test))\n",
    "\n",
    "selected_img = np.array([x_test[random_idx]])\n",
    "show_image(selected_img)\n",
    "\n",
    "result_num = np.argmax(model.predict(selected_img)[0])\n",
    "print('* result number is: {}'.format(result_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "10000/1 - 0s - loss: 0.0410 - accuracy: 0.9760\n",
      "* finish test, lost is 0.07981035743718967, accuracy is 0.9760000109672546\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result number is: 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('* train and test data loaded, shape is: {}'.format(x_train.shape))\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "        tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "        tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "        tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_num_dense'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "random_idx = rdm.randint(0, len(x_test))\n",
    "\n",
    "selected_img = np.array([x_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img)\n",
    "\n",
    "result_num = np.argmax(model.predict(selected_img)[0])\n",
    "print('* result number is: {}'.format(result_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refer to: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "10000/1 - 0s - loss: 0.2724 - accuracy: 0.8804\n",
      "* finish test, lost is 0.3378541542828083, accuracy is 0.8804000020027161\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result is \"Sneaker\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "(imgs_train, labels_train), (imgs_test, labels_test) = data.load_data()\n",
    "imgs_train, imgs_test = imgs_train / 255.0, imgs_test / 255.0\n",
    "print('* train and test data loaded, shape is: {}'.format(imgs_train.shape))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "    tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_fashion_dense'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(imgs_train, labels_train, epochs=10)\n",
    "    save_weights(model, model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(imgs_test, labels_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "random_idx = rdm.randint(0, len(imgs_test))\n",
    "\n",
    "selected_img = np.array([imgs_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img)\n",
    "\n",
    "result_idx = np.argmax(model.predict(selected_img)[0])\n",
    "result_cls = class_names[result_idx]\n",
    "print('* result is \"{}\"'.format(result_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28, 1)\n",
      "10000/1 - 4s - loss: 0.1344 - accuracy: 0.9294\n",
      "* finish test, lost is 0.21741625018417834, accuracy is 0.9294000267982483\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result is \"Dress\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "(imgs_train, labels_train), (imgs_test, labels_test) = data.load_data()\n",
    "imgs_train, imgs_test = imgs_train / 255.0, imgs_test / 255.0\n",
    "imgs_train, imgs_test = imgs_train.reshape(-1, 28, 28, 1), imgs_test.reshape(-1, 28, 28, 1)\n",
    "print('* train and test data loaded, shape is: {}'.format(imgs_train.shape))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),  # dropout 正则化\n",
    "    tf.keras.layers.Flatten(),  # 平面化\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "    tf.keras.layers.Dropout(0.5),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_fashion_cnn'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(imgs_train, labels_train, epochs=10)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(imgs_test, labels_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "random_idx = rdm.randint(0, len(imgs_test))\n",
    "\n",
    "selected_img = np.array([imgs_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img.reshape(28, 28))\n",
    "\n",
    "result_idx = np.argmax(model.predict(selected_img)[0])\n",
    "result_cls = class_names[result_idx]\n",
    "print('* result is \"{}\"'.format(result_cls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
