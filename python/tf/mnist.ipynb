{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refer to: https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "10000/1 - 0s - loss: 0.1936 - accuracy: 0.9268\n",
      "* finish test, lost is 0.2708414345532656, accuracy is 0.926800012588501\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFJElEQVR4nO2cT2gcVRzHP9+memgjGyWhLVrU2kLpqVJrBSl4kYoUqraIPSwWLGkhBSUeLEIgxxxUepNWLEgjZIUI7U2kUXKTNqWoTYhpxe2/2BDQWAPFdvPzsDPbtMluptmdN53J+8CwO2925v32my+/fW/mlyczwxMvy5IOYCngRXaAF9kBXmQHeJEd4EV2QF0iS3pN0qiki5IONyqorKHFjpMlNQG/Aa8CV4EzwF4zG25ceNlgeR3nvghcNLPfAST1AbuAqiJLyuzMx8xU7Vg96eJJ4Mqs/atB2z1Iapd0VtLZOvpKNfU4ORJmdgw4Btl2ci3qcfI1YO2s/aeCNs991CPyGWCDpGclPQq8A5xqTFjZYtHpwszuSDoEfAc0AcfN7ELDIssQix7CLaqzDOfkuEYXnojEPrqIg66uLgC6u7sBuH79OgA7duwAYHj44ZoPeSc7IJVOXr16NQAzMzP37O/fvx+Azs7OZAKrgneyA1IpcqFQoFAoMDU1xdTUVKW9paWFlpYW1q9fn2B0c0mlyGkj1ePkI0eOANDR0THn2J49ewA4efJkI7usih8nJ0wqRxdRCEcarpxcC+9kB6TayaOjowDcunULgBUrVlSONTU1JRLTfHgnOyDVo4uQ0NHr1q2rtF25Un4ytm/fPgAGBwfj6LqCH10kTCacPDAwAMD27dsrbcuWlf0zMTEBwLZt2wC4fPlyHCF4JydNJpwc3qsYGRmptIVODu/Ubdy4EYBLly7FEYJ3ctJkwskrV64EoKenB4CDBw/OcXJfXx8A+Xw+jhBqOjnVk5GQ6elpAMbGxoByqghFDtm6davzuEJ8unBAJpwcEqa+MEXMft/a2grA7t27Aejv73cWl3eyAzLl5FrkcjkAjh49CsDy5eWvXigUYu/bO9kBS8bJIaGje3t7Ae/kzOBFdoAX2QELiixpraQfJA1LuiDp/aD9CUnfSxoLXh+PP9wFY0VSZcYXZXNBlF7uAB+a2SbgJaBD0ibgMHDazDYAp4N9zzwsOLows3FgPHh/U9II5f9y2gW8EnzsK+BH4KNYooxIrRlfkjzQEE7SM8DzwE/AquAPAPAnsKrKOe1A++JDzABmFmkDmoEh4K1g/+/7jv8V4RoW55bL5SyXy9mJEyesVCpZqVSy27dvz7sVi0UrFosN67vW946U+SU9AvQDX5vZt0HzDUlrguNrgIko11qKLJguJAn4Ehgxs89mHToFvAv0BK+J10OFZbT5fJ7m5mYAdu7cOe9n29vdZbAoOfllIA/8Iul80PYxZXG/kfQeUATejifE9JOJx0/z0dbWBty967ZlyxbgroOHhoYAmJycbEh//kFqwmTWya7xTk4YL7IDvMgO8CI7wIvsAC+yA7zIDnD9tHoSmA5e00orc+N/utYJTicjAJLOmtkLTjttIIuJ36cLB3iRHZCEyMcS6LORPHD8znPyUsSnCwd4kR3gTOQ0Lmhdo3qqW9I1SeeD7fWa13GRk9O6oHXwFH6NmZ2T9Bjlkog3KD/P/NfMPolyHVdOrixobWb/AeGC1g81ZjZuZueC9zeBsHrqgXAlcqQFrR9m7queAjgk6WdJxxcqtvQ/fBGQ1Ey5uOcDM/sH+Bx4DthMuU7w01rnuxI5tQtaz1c9ZWY3zKxkZjPAF5TTYVVciZzKBa2rVU+F5WkBbwK/1rqOk1udKV7Qulr11F5JmykXG/4BHKh1ET+tdoD/4XOAF9kBXmQHeJEd4EV2gBfZAV5kB/wPb9xReNZJ7/8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result number is: 1\n"
     ]
    }
   ],
   "source": [
    "import random as rdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('* train and test data loaded, shape is: {}'.format(x_train.shape))\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_num_softmax'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "random_idx = rdm.randint(0, len(x_test))\n",
    "\n",
    "selected_img = np.array([x_test[random_idx]])\n",
    "show_image(selected_img)\n",
    "\n",
    "result_num = np.argmax(model.predict(selected_img)[0])\n",
    "print('* result number is: {}'.format(result_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "10000/1 - 0s - loss: 0.0410 - accuracy: 0.9760\n",
      "* finish test, lost is 0.07981035743718967, accuracy is 0.9760000109672546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result number is: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('* train and test data loaded, shape is: {}'.format(x_train.shape))\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "        tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "        tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "        tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_num_dense'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "random_idx = rdm.randint(0, len(x_test))\n",
    "\n",
    "selected_img = np.array([x_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img)\n",
    "\n",
    "result_num = np.argmax(model.predict(selected_img)[0])\n",
    "print('* result number is: {}'.format(result_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refer to: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "10000/1 - 1s - loss: 0.2724 - accuracy: 0.8804\n",
      "* finish test, lost is 0.3378541542828083, accuracy is 0.8804000020027161\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result is \"Dress\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "(imgs_train, labels_train), (imgs_test, labels_test) = data.load_data()\n",
    "imgs_train, imgs_test = imgs_train / 255.0, imgs_test / 255.0\n",
    "print('* train and test data loaded, shape is: {}'.format(imgs_train.shape))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "    tf.keras.layers.Dropout(0.2),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_fashion_dense'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(imgs_train, labels_train, epochs=10)\n",
    "    save_weights(model, model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(imgs_test, labels_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "random_idx = rdm.randint(0, len(imgs_test))\n",
    "\n",
    "selected_img = np.array([imgs_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img)\n",
    "\n",
    "result_idx = np.argmax(model.predict(selected_img)[0])\n",
    "result_cls = class_names[result_idx]\n",
    "print('* result is \"{}\"'.format(result_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train and test data loaded, shape is: (60000, 28, 28, 1)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "10000/1 - 3s - loss: 0.1344 - accuracy: 0.9294\n",
      "* finish test, lost is 0.21741625018417834, accuracy is 0.9294000267982483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* result is \"T-shirt/top\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from utils import load_weights, save_weights, show_image\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "(imgs_train, labels_train), (imgs_test, labels_test) = data.load_data()\n",
    "imgs_train, imgs_test = imgs_train / 255.0, imgs_test / 255.0\n",
    "imgs_train, imgs_test = imgs_train.reshape(-1, 28, 28, 1), imgs_test.reshape(-1, 28, 28, 1)\n",
    "print('* train and test data loaded, shape is: {}'.format(imgs_train.shape))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # 输入层，输入 28 点阵图片\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),  # dropout 正则化\n",
    "    tf.keras.layers.Flatten(),  # 平面化\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # 128 神经元的全连接层\n",
    "    tf.keras.layers.Dropout(0.5),  # dropout 正则化\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # 10 单元的 softmax 层作为输出\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_path = 'models/mnist_fashion_cnn'\n",
    "if not load_weights(model, model_path=model_path):\n",
    "    model.fit(imgs_train, labels_train, epochs=10)\n",
    "    save_weights(model, model_path=model_path)\n",
    "\n",
    "lost, accuracy = model.evaluate(imgs_test, labels_test, verbose=2)\n",
    "print('* finish test, lost is {}, accuracy is {}'.format(lost, accuracy))\n",
    "\n",
    "random_idx = rdm.randint(0, len(imgs_test))\n",
    "\n",
    "selected_img = np.array([imgs_test[random_idx]])  # select random image from test list\n",
    "show_image(selected_img.reshape(28, 28))\n",
    "\n",
    "result_idx = np.argmax(model.predict(selected_img)[0])\n",
    "result_cls = class_names[result_idx]\n",
    "print('* result is \"{}\"'.format(result_cls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
