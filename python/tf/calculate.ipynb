{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数学计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 引入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import e as E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义一个张量转字符串的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_str(vt):\n",
    "    s = '\\n{} (shape={}, type={})'.format(vt, vt.shape, vt.dtype)\n",
    "    return '{}'.format(s.replace('\\n', '\\n\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.add(t1, t2)`表示向量相加，等价于`t1 + t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 + t2\n",
    "print('\\n* then \"t1 + t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.add(t1, t2)\n",
    "print('\\n* then \"tf.add(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 减法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.subtract(t1, t2)`表示向量相加，等价于`t1 - t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 - t2\n",
    "print('\\n* then \"t1 - t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.subtract(t1, t2)\n",
    "print('\\n* then \"tf.subtract(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘法（内积）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.multiply(t1, t2)`表示向量相乘，等价于`t1 * t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 * t2\n",
    "print('\\n* then \"t1 * t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.multiply(t1, t2)\n",
    "print('\\n* then \"tf.multiply(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘法（点积）\n",
    "\n",
    "- 点积乘法要求:\n",
    "    - 相乘的两个张量的**阶**必须大于等于`2`（即表示为**矩阵**或**矩阵的集合**）\n",
    "    - 参与运算的两个张量`(t1, t2)`的**阶**必须满足如下需求：\n",
    "        - 从倒数第三个轴开始，`t1`和`t2`对应轴的元素数量必须相同\n",
    "        - `t1`的最后一个轴元素数量必须和`t2`倒数第二个轴元素数量相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 点积乘法在张量的阶为`2`时，等价为矩阵相乘，即第一个矩阵的每一行元素和第二个矩阵的每一列对应元素相乘并求和，组成新的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((3, 2), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 @ t2\n",
    "print('\\n* then \"t1 @ t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.matmul(t1, t2)\n",
    "print('\\n* then \"tf.matmul(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 点积乘法在张量的阶大于`2`时，相当于一批矩阵和另一批矩阵分步依次相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3, 2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((1, 2, 3, 2), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果阶数不同或其它轴上项数不同，则需要对形状较小的张量进行广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3, 2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n\\n* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((1, 3, 2), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = tf.matmul(t1, t2)\n",
    "print('\\n* then \"t1 • t2\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 除法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.divide(t1, t2)`表示向量相除，等价于`t1 / t2`\n",
    "- 两个形状相同的张量可以相除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 / t2\n",
    "print('\\n* then \"t1 / t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.divide(t1, t2)\n",
    "print('\\n* then \"tf.divide(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 地板除只保留相除结果的整数部分\n",
    "- `tf.math.floordiv(t1, t2)`表示向量相除，等价于`t1 // t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((1, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 // t2\n",
    "print('\\n* then \"t1 // t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.math.floordiv(t1, t2)\n",
    "print('\\n* then \"tf.math.floordiv(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模运算\n",
    "\n",
    "- 模运算获取相除的余数，运算规则与除法相同\n",
    "- `tf.math.mod(t1, t2)`表示取余数，获取，等价于`tf.math.floormod(t1, t2)`以及`t1 % t2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((3,), minval=-6, maxval=-1, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 % t2\n",
    "print('\\n* then \"t1 % t2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.math.mod(t1, t2)\n",
    "print('\\n* then \"tf.math.mod(t1, t2)\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.math.floormod(t1, t2)\n",
    "print('\\n* then \"tf.math.floormod(t1, t2)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播\n",
    "\n",
    "- 基本运算（`+`，`-`，`*`，`/`）都支持对操作数进行广播；\n",
    "- 广播的定义：\n",
    "    - 当两个阶数不同的张量进行运算时，如果没有歧义的话，较小的张量会被广播，以匹配较大张量的形状\n",
    "    - 广播包含以下两步：\n",
    "        1. 向较小的张量添加轴（称为广播轴），使其`dim`与较大的张量相同\n",
    "        2. 将较小的张量沿着新轴重复，使其形状与较大的张量相同\n",
    "    - 例如：\n",
    "        - `t1(2, 3)`和`t2(1, 3)`相加，因为两个张量的阶数相同，则只需对`t2(1, 3)`沿第一个轴复制，将其扩展到`t2(2, 3)`\n",
    "        - `t1(2, 3)`和`t2(3)`相加，需要对`t2(3)`扩展第一个轴，将其变为`t2(1, 3)`，再沿第一个轴复制，将其扩展到`t2(2, 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 维度相同时，参与运算的两个张量必须符合如下特征：\n",
    "    - 自右向左，作为操作数张量的轴元素数必须和被操作张量相同或必须为`1`\n",
    "    - 例如：`t(2, 3, 4)`可以和`t(2, 3, 4)`, `t(1, 3, 4)`, `t(1, 1, 4)`运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((1, 1, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 + t2\n",
    "print('\\n* then \"t1 + t2\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 维度不同时，参与运算的两个张量必须符合如下特征：\n",
    "    - 被操作数的维度可以少于操作数维度，但自右向左的元素个数必须相同或必须为`1`\n",
    "    - 例如：`t(2, 3, 4)`可以和`t(3, 4)`, `t(4,)`, `t(1, 4)`等相运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((2, 3, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.random.uniform((1, 4), minval=1, maxval=6, dtype=tf.int32)\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = t1 / t2\n",
    "print('\\n* then \"t1 * t2\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指数、开方、对数，绝对值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指数运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对一个张量进行指数运算，相当于对张量中的每个元素进行指数运算\n",
    "- 指数运算的结果的形状和被计算张量一致\n",
    "- `tf.square(t)`函数特指求平方，即 $t^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print('* when t is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.pow(t, 2)\n",
    "print('\\n* then \"tf.pow(t, 2)\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = t ** 2\n",
    "print('\\n* then \"t ** 2\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.square(t)\n",
    "print('\\n* then \"tf.square(t)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.exp(t)`表示对张量中的每个元素求$e^x$，形成新的张量。（$x$表示张量中的各个元素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 2.], [3., 4.]])\n",
    "print('* when t is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.exp(t)\n",
    "print('\\n* then \"tf.exp(t)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开方运算\n",
    "\n",
    "- 对一个张量进行开方运算，相当于对张量中的每个元素进行开方运算\n",
    "- 开方运算的结果的形状和被计算张量一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 9.], [16., 100.]])\n",
    "print('* when t is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.sqrt(t)\n",
    "print('\\n* then \"tf.exp(t)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.math.log`求的是以自然常数`𝑒`为底的对数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([E, E ** 2, E ** 3])\n",
    "print('* when t is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.math.log(t)\n",
    "print('\\n* then \"tf.math.log(t)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 求任意底数的对数，可以借助公式 $log_xy = \\frac{log_ey}{log_ex}$ 进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant([[1., 9.], [16., 100.]])\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t1)))\n",
    "\n",
    "t2 = tf.constant([[2., 3.], [2., 10.]])\n",
    "print('\\n* and t2 is:{}'.format(tensor_to_str(t2)))\n",
    "\n",
    "t_ = tf.math.log(t1) / tf.math.log(t2)\n",
    "print('\\n* and \"log(t2)t1\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求绝对值\n",
    "\n",
    "- 张量的绝对值，相当于张量中每个元素求绝对值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.random.uniform((2, 3, 4), minval=-6, maxval=6, dtype=tf.int32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.abs(t)\n",
    "print('\\n* and \"tf.abs(t)\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 范数\n",
    "\n",
    "- 向量$v$的$p$范数可以按如下公式计算：\n",
    "$$|v||_p = [\\sum_{k=0}^N|v_k|p]^\\frac{1}{p}$$\n",
    "- 当 $p=1$, $p=2$时分别叫做`1`范数，`2`范数。除此以外，还有无穷范数：\n",
    "$$|v||_{+\\infty}=max(|v(i)|)$$\n",
    "$$|v||_{-\\infty}=max(|v(i)|)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 范数\n",
    "\n",
    "- 曼哈顿距离、最小绝对误差等即 L1 范数\n",
    "- L1 范数可以度量两个向量间的差异，如绝对误差和 (Sum of Absolute Difference)\n",
    "- L1 范数相当于向量中每个元素绝对值的和，即 $||x||_1=\\sum_{i=1}^{N}{|x_i|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.random.uniform((2, 2, 2, 1), minval=-1, maxval=6, dtype=tf.float32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.norm(t, ord=1)\n",
    "print('\\n* and \"tf.norm(t, ord=1)\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.reduce_sum(tf.abs(t))\n",
    "print('\\n* and \"tf.reduce_sum(tf.abs(t))\" is:{}'.format(tensor_to_str(t_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 范数\n",
    "\n",
    "- 欧氏距离即 L2 范数\n",
    "- L2 范数可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）\n",
    "- L2 范数相当于向量元素绝对值的平方和再开平方 $||x||_2=\\sqrt{\\sum_{i=1}^{N}{x_i^2}}$\n",
    "- `tf.norm`函数的`ord`参数默认为`2`，即 L2 范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.random.uniform((2, 2, 2, 1), minval=-1, maxval=6, dtype=tf.float32)\n",
    "print('* when t1 is:{}'.format(tensor_to_str(t)))\n",
    "\n",
    "t_ = tf.norm(t, ord=2)\n",
    "print('\\n* and \"tf.norm(t, ord=2)\" is:{}'.format(tensor_to_str(t_)))\n",
    "\n",
    "t_ = tf.sqrt(tf.reduce_sum(tf.square(t)))\n",
    "print('\\n* and \"tf.sqrt(tf.reduce_sum(tf.square(t)))\" is:{}'.format(tensor_to_str(t_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
