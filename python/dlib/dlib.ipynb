{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dlib Demo\n",
    "\n",
    "> Refer to: https://github.com/ageitgey/face_recognition/blob/master/face_recognition/api.py\n",
    "\n",
    "> Refer to: http://dlib.net, http://dlib.net/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dlib model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile, ImageDraw\n",
    "\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dlib_face_recognition_resnet_model_v1 = 'dlib_face_recognition_resnet_model_v1.dat'\n",
    "mmod_human_face_detector = 'mmod_human_face_detector.dat'\n",
    "shape_predictor_5_face_landmarks = 'shape_predictor_5_face_landmarks.dat'\n",
    "shape_predictor_68_face_landmarks = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import curdir, path\n",
    "from itertools import chain\n",
    "\n",
    "import glob\n",
    "import random as rdm\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        pic_dir = path.abspath(path.join(curdir, 'pics'))\n",
    "        pic_files = set(glob.glob(path.join(pic_dir, '**/*.jpg')))\n",
    "        self._dataset = self._make_dataset(pic_files)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_dataset(pic_files):\n",
    "        dataset = {}\n",
    "        for pf in pic_files:\n",
    "            key = path.split(path.dirname(pf))[1]\n",
    "            if key in dataset:\n",
    "                dataset[key].append(pf)\n",
    "            else:\n",
    "                dataset[key] = [pf]\n",
    "        return dataset\n",
    "\n",
    "    def one_face(self):\n",
    "        key = rdm.choice(list(self._dataset.keys()))\n",
    "        return key, rdm.choice(self._dataset[key])\n",
    "\n",
    "    def fetch(self, split_count=1):\n",
    "        train_labels, train_data, test_labels, test_data = [], [], [], []\n",
    "        for name, files in self._dataset.items():\n",
    "            test_indices = np.random.choice(len(files), split_count)\n",
    "            data_indices = np.setdiff1d(np.arange(len(files)), test_indices)\n",
    "\n",
    "            files = np.array(files)\n",
    "            train_labels += np.repeat(name, len(data_indices)).tolist()\n",
    "            train_data += files[data_indices].tolist()\n",
    "\n",
    "            test_labels += np.repeat(name, len(test_indices)).tolist()\n",
    "            test_data += files[test_indices].tolist()\n",
    "\n",
    "        return train_labels, train_data, test_labels, test_data\n",
    "\n",
    "\n",
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectange(img, rect, outline='#fff'):\n",
    "    for n in range(0, 5):\n",
    "        box = [(rect[0][0] + n, rect[0][1] + n), (rect[1][0] - n, rect[1][1] - n)]\n",
    "        draw.rectangle(box, outline=outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dlib model download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bz2\n",
    "from os import curdir, path, makedirs, rename\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def download_model(model_file):\n",
    "    def make_model_path(model_file, middle_path=''):\n",
    "        base_dir = path.abspath(path.join(curdir, 'models', middle_path))\n",
    "        if not path.exists(base_dir):\n",
    "            makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "        return path.join(base_dir, model_file)\n",
    "\n",
    "    local_model_file = make_model_path(model_file)\n",
    "    if path.exists(local_model_file):\n",
    "        print('* model file \"{}\" exsits'.format(model_file))\n",
    "        return local_model_file\n",
    "\n",
    "    print('* model file \"{}\" not exsits'.format(model_file))\n",
    "\n",
    "    def unzip_bz2(src_file, dest_file):\n",
    "        with bz2.BZ2File(src_file, 'rb') as src_fp, open(dest_file, 'wb') as dest_fp:\n",
    "            while 1:\n",
    "                data = src_fp.read(100 * (1024 ** 2))\n",
    "                if not data:\n",
    "                    break\n",
    "                dest_fp.write(data)\n",
    "\n",
    "    bz2_model_file = '{}.bz2'.format(model_file)\n",
    "    bz2_local_model_file = make_model_path(bz2_model_file, middle_path='.cache')\n",
    "    if path.exists(bz2_local_model_file):\n",
    "        print('* model bz2 file \"{}\" exsits, uncompress it...'.format(bz2_local_model_file))\n",
    "        unzip_bz2(bz2_local_model_file, local_model_file)\n",
    "\n",
    "        print('* model bz2 file \"{}\" uncompressed, save as \"{}\"'.format(bz2_local_model_file, local_model_file))\n",
    "        return local_model_file\n",
    "\n",
    "    download_url = urljoin('http://dlib.net/files/', bz2_model_file)\n",
    "    print('* begin download from url \"{}\"'.format(download_url))\n",
    "\n",
    "    r = requests.get(download_url, stream=True, verify=False)\n",
    "    total_size = int(r.headers.get('Content-Length', -1))\n",
    "    print('* total file size is {}'.format(total_size))\n",
    "\n",
    "    download_size = 0\n",
    "    download_tmp_file = '{}__download.tmp'.format(bz2_local_model_file)\n",
    "    with open(download_tmp_file, 'wb') as fp:\n",
    "        print('* create download file \"{}\"'.format(download_tmp_file))\n",
    "        for chunk in r.iter_content(chunk_size=10 * (1024 ** 2)):\n",
    "            if chunk:\n",
    "                fp.write(chunk)\n",
    "                download_size += len(chunk)\n",
    "                print('* {:.2f}kb downloaded'.format(download_size / 1024), end='\\r')\n",
    "            else:\n",
    "                print('* download completed')\n",
    "\n",
    "    rename(download_tmp_file, bz2_local_model_file)\n",
    "    print('* rename \"{}\" to \"{}\"'.format(download_tmp_file, bz2_local_model_file))\n",
    "\n",
    "    unzip_bz2(bz2_local_model_file, local_model_file)\n",
    "    print('* model bz2 file \"{}\" uncompressed, save as \"{}\"'.format(bz2_local_model_file, local_model_file))\n",
    "    \n",
    "    return local_model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load face image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "_, face_file = dataset.one_face()\n",
    "detect_im = np.array(Image.open(face_file).convert('RGB'))\n",
    "\n",
    "plt.imshow(detect_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "boxes = face_detector(detect_im, 1)\n",
    "print('* {} faces detected, boxes is \"{}\"'.format(len(boxes), boxes))\n",
    "\n",
    "img = Image.fromarray(detect_im)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for box in boxes:\n",
    "    box = [(box.left(), box.top()), (box.right(), box.bottom())]\n",
    "    draw_rectange(draw, box, outline='#fff')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "if 'cnn_face_detector' not in locals():\n",
    "    model_file = download_model(mmod_human_face_detector)\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1(model_file)\n",
    "\n",
    "boxes = [b.rect for b in cnn_face_detector(detect_im, 1)]\n",
    "print('* {} faces detected, boxes is \"{}\"'.format(len(boxes), boxes))\n",
    "\n",
    "img = Image.fromarray(detect_im)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for box in boxes:\n",
    "    box = [(box.left(), box.top()), (box.right(), box.bottom())]\n",
    "    draw_rectange(draw, box, outline='#fff')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face landmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 points landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "if 'pose_predictor_5_point' not in locals():\n",
    "    model_file = download_model(shape_predictor_5_face_landmarks)\n",
    "    pose_predictor_5_point = dlib.shape_predictor(model_file)\n",
    "\n",
    "raw_landmarks = [pose_predictor_5_point(detect_im, b) for b in boxes]\n",
    "landmarks = [[(p.x, p.y) for p in landmark.parts()] for landmark in raw_landmarks]\n",
    "\n",
    "img = Image.fromarray(detect_im)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for points in landmarks:\n",
    "    for p in points:\n",
    "        draw.ellipse((p[0] - 5, p[1] - 5, p[0] + 5, p[1] + 5), fill='#fff')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68 points landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "if 'pose_predictor_68_point' not in locals():\n",
    "    model_file = download_model(shape_predictor_68_face_landmarks)\n",
    "    pose_predictor_68_point = dlib.shape_predictor(model_file)\n",
    "    \n",
    "raw_landmarks = [pose_predictor_68_point(detect_im, b) for b in boxes]\n",
    "landmarks = [[(p.x, p.y) for p in landmark.parts()] for landmark in raw_landmarks]\n",
    "\n",
    "img = Image.fromarray(detect_im)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for points in landmarks:\n",
    "    for p in points:\n",
    "        draw.ellipse((p[0] - 5, p[1] - 5, p[0] + 5, p[1] + 5), fill='#fff')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "if len(landmarks[0]) == 5:\n",
    "    named_landmarks = [{\n",
    "        'nose_tip': [points[4]],\n",
    "        'left_eye': points[2:4],\n",
    "        'right_eye': points[0:2],\n",
    "    } for points in landmarks]\n",
    "else:\n",
    "    named_landmarks = [{\n",
    "        'chin': points[0:17],\n",
    "        'left_eyebrow': points[17:22],\n",
    "        'right_eyebrow': points[22:27],\n",
    "        'nose_bridge': points[27:31],\n",
    "        'nose_tip': points[31:36],\n",
    "        'left_eye': points[36:42],\n",
    "        'right_eye': points[42:48],\n",
    "        'top_lip': points[48:55] + [points[64]] + [points[63]] + [points[62]] + [points[61]] + [points[60]],\n",
    "        'bottom_lip': points[54:60] + [points[48]] + [points[60]] + [points[67]] + [points[66]] + [points[65]] + [points[64]]\n",
    "    } for points in landmarks]\n",
    "\n",
    "img = Image.fromarray(detect_im)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "def draw_points(points, color):\n",
    "    for p in points:\n",
    "        draw.ellipse((p[0] - 5, p[1] - 5, p[0] + 5, p[1] + 5), fill=color)\n",
    "\n",
    "for nl in named_landmarks:\n",
    "    if 'chin' in nl:\n",
    "        draw_points(nl['chin'], color='#F00')\n",
    "        \n",
    "    if 'left_eyebrow' in nl and 'right_eyebrow' in nl:\n",
    "        draw_points(nl['left_eyebrow'], color='#0F0')\n",
    "        draw_points(nl['right_eyebrow'], color='#0F0')\n",
    "        \n",
    "    if 'nose_bridge' in nl:\n",
    "        draw_points(nl['nose_bridge'], color='#00F')\n",
    "        \n",
    "    if 'nose_tip' in nl:\n",
    "        draw_points(nl['nose_tip'], color='#FF0')\n",
    "        \n",
    "    if 'left_eye' in nl and 'right_eye' in nl:\n",
    "        draw_points(nl['left_eye'], color='#F0F')\n",
    "        draw_points(nl['right_eye'], color='#F0F')\n",
    "        \n",
    "    if 'top_lip' in nl and 'bottom_lip' in nl:\n",
    "        draw_points(nl['top_lip'], color='#0FF')\n",
    "        draw_points(nl['bottom_lip'], color='#0FF')\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_labels, raw_train_data, raw_test_labels, raw_test_data = dataset.fetch()\n",
    "print('* load {} picture for tainning, and {} pictures for testing'.format(len(raw_train_labels), len(raw_test_labels)))\n",
    "\n",
    "raw_train_data = [np.array(Image.open(file).convert('RGB')) for file in raw_train_data]\n",
    "raw_test_data = [np.array(Image.open(file).convert('RGB')) for file in raw_test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load face recognize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'face_detector' not in locals():\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "if 'pose_predictor_5_point' not in locals():\n",
    "    model_file = download_model(shape_predictor_5_face_landmarks)\n",
    "    pose_predictor_5_point = dlib.shape_predictor(model_file)\n",
    "\n",
    "if 'face_encoder' not in locals():\n",
    "    model_file = download_model(dlib_face_recognition_resnet_model_v1)\n",
    "    face_encoder = dlib.face_recognition_model_v1(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoding all faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "def encoding_faces(label, im):\n",
    "    locations = face_detector(im)\n",
    "    landmarks = [pose_predictor_5_point(im, l) for l in locations]\n",
    "    return (list(repeat(im, len(locations))),\n",
    "            list(repeat(label, len(locations))),\n",
    "            [face_encoder.compute_face_descriptor(im, landmark, 2) for landmark in landmarks])\n",
    "\n",
    "\n",
    "train_ims, train_labels, train_encodings = [], [], []\n",
    "for name, im in zip(raw_train_labels, raw_train_data):\n",
    "    ims, labels, encodings = encoding_faces(name, im)\n",
    "    train_ims += ims\n",
    "    train_labels += labels\n",
    "    train_encodings += encodings\n",
    "\n",
    "train_encodings = np.array(train_encodings)\n",
    "\n",
    "test_ims, test_labels, test_encodings = [], [], []\n",
    "for name, im in zip(raw_test_labels, raw_test_data):\n",
    "    ims, labels, encodings = encoding_faces(name, im)\n",
    "    test_ims += ims\n",
    "    test_labels += labels\n",
    "    test_encodings += encodings\n",
    "\n",
    "test_encodings = np.array(test_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for im, name, encoding in zip(test_ims, test_labels, test_encodings):\n",
    "    distances = np.linalg.norm(train_encodings - encoding, axis=1)\n",
    "    index = np.argmin(distances)\n",
    "\n",
    "    print('* give picture of {}'.format(name))\n",
    "    plt.imshow(Image.fromarray(im))\n",
    "    plt.show()\n",
    "\n",
    "    print('* recognized picture of {}'.format(train_labels[index]))\n",
    "    img = Image.fromarray(train_ims[index])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define classifier match function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier):\n",
    "    matched_indices = classifier.predict(face_encodings)\n",
    "    matched_encodings = train_encodings[matched_indices]\n",
    "    matched_results = np.linalg.norm(matched_encodings - test_encodings, axis=1) <= 0.4\n",
    "    \n",
    "    for i, mr in enumerate(matched_results):\n",
    "        if mr:\n",
    "            print('* give picture of {}'.format(test_labels[i]))\n",
    "            plt.imshow(Image.fromarray(test_ims[i]))\n",
    "            plt.show()\n",
    "\n",
    "            index = matched_indices[i]\n",
    "\n",
    "            print('* recognized picture of {}'.format(train_labels[index]))\n",
    "            img = Image.fromarray(train_ims[index])\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "n_estimators = 10\n",
    "\n",
    "svm_clf = svm.SVC(gamma='scale', kernel='rbf', random_state=0, C=1, probability=True)\n",
    "svm_clf.fit(train_encodings, list(range(len(train_encodings))))\n",
    "\n",
    "classify(svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn import neighbors\n",
    "\n",
    "jobs_num = cpu_count()\n",
    "\n",
    "n_neighbors = min(int(round(sqrt(len(train_encodings)))), 5)\n",
    "print('* number of neighbors is: {}'.format(n_neighbors))\n",
    "\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                                         algorithm='ball_tree',\n",
    "                                         weights='distance',\n",
    "                                         n_jobs=jobs_num)\n",
    "knn_clf.fit(train_encodings, list(range(len(train_encodings))))\n",
    "\n",
    "classify(knn_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
